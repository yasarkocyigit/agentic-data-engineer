# =============================================================
# AIRFLOW AGENTIC AI - Full Stack Docker Compose
# Services: Spark, MinIO, Marquez, Airflow
# =============================================================

services:
  # ---------------------------------------------------------
  # SPARK MASTER
  # ---------------------------------------------------------
  spark-master:
    image: apache/spark:4.1.1
    container_name: spark_master
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "8082:8080" # Spark Master UI (8082 to avoid conflict)
      - "7077:7077" # Spark Master port
    volumes:
      - ./notebooks:/opt/spark/work/notebooks
      - ./config:/opt/spark/work/config
      - ./jars:/opt/spark/extra-jars
    networks:
      - agentic-network

  # ---------------------------------------------------------
  # SPARK WORKER
  # ---------------------------------------------------------
  spark-worker:
    image: apache/spark:4.1.1
    container_name: spark_worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_DIR=/tmp/spark-worker
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-master
    volumes:
      - ./notebooks:/opt/spark/work/notebooks
      - ./config:/opt/spark/work/config
      - ./jars:/opt/spark/extra-jars
    networks:
      - agentic-network

  # ---------------------------------------------------------
  # MINIO (S3-Compatible Object Storage for Delta Lake)
  # ---------------------------------------------------------
  minio:
    image: minio/minio:latest
    container_name: minio_lakehouse
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: admin123
    ports:
      - "9000:9000" # MinIO API
      - "9001:9001" # MinIO Console
    volumes:
      - minio_data:/data
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9000/minio/health/live" ]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - agentic-network

  # MinIO Client - Create initial buckets
  minio-setup:
    image: minio/mc:latest
    container_name: minio_setup
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c " /usr/bin/mc alias set myminio http://minio:9000 admin admin123; /usr/bin/mc mb myminio/bronze --ignore-existing; /usr/bin/mc mb myminio/silver --ignore-existing; /usr/bin/mc mb myminio/gold --ignore-existing; /usr/bin/mc mb myminio/warehouse --ignore-existing; /usr/bin/mc mb myminio/checkpoints --ignore-existing; echo 'Buckets created successfully!'; exit 0; "
    networks:
      - agentic-network

  # ---------------------------------------------------------
  # TRINO (SQL Query Engine for Iceberg)
  # ---------------------------------------------------------
  trino:
    image: trinodb/trino:latest
    container_name: trino_sql
    volumes:
      - ./trino/etc:/etc/trino
    ports:
      - "8083:8080"
    depends_on:
      minio:
        condition: service_healthy
    networks:
      - agentic-network

  # ---------------------------------------------------------
  # MARQUEZ (OpenLineage Data Lineage)
  # ---------------------------------------------------------
  marquez-db:
    image: postgres:17
    container_name: marquez_db
    environment:
      POSTGRES_USER: marquez
      POSTGRES_PASSWORD: marquez
      POSTGRES_DB: marquez
    volumes:
      - marquez_db_data:/var/lib/postgresql/data
    networks:
      - agentic-network

  marquez:
    image: marquezproject/marquez:latest
    platform: linux/amd64
    container_name: marquez_lineage
    environment:
      - MARQUEZ_PORT=5000
      - MARQUEZ_ADMIN_PORT=5001
      - POSTGRES_HOST=marquez-db
      - POSTGRES_PORT=5432
      - POSTGRES_DB=marquez
      - POSTGRES_USER=marquez
      - POSTGRES_PASSWORD=marquez
    ports:
      - "5002:5000" # Marquez API (5002 to avoid Mac AirPlay conflict)
      - "5003:5001" # Marquez Admin
    depends_on:
      - marquez-db
    networks:
      - agentic-network

  marquez-web:
    image: marquezproject/marquez-web:latest
    platform: linux/amd64
    container_name: marquez_web
    environment:
      - MARQUEZ_HOST=marquez
      - MARQUEZ_PORT=5000
      - WEB_PORT=3000
    ports:
      - "8085:3000" # Marquez Web UI (Changed from 3002)
    depends_on:
      - marquez
    networks:
      - agentic-network

  # ---------------------------------------------------------
  # AIRFLOW 3.x (Orchestration)
  # ---------------------------------------------------------
  airflow-init:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow_init
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:Gs+163264128@host.docker.internal:5433/controldb
      - AIRFLOW__CORE__FERNET_KEY=zTvhk7Vf2dHkL5j8g3nM9pQrYwXy4bCfE6HiJkLoNsU=
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__WEBSERVER__SECRET_KEY=super-secret-key-for-airflow
    entrypoint: >
      /bin/bash -c " airflow db migrate; airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com; echo 'Airflow initialized!'; "
    networks:
      - agentic-network

  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow_webserver
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:Gs+163264128@host.docker.internal:5433/controldb
      - AIRFLOW__CORE__FERNET_KEY=zTvhk7Vf2dHkL5j8g3nM9pQrYwXy4bCfE6HiJkLoNsU=
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__WEBSERVER__SECRET_KEY=super-secret-key-for-airflow
      - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth
      - AIRFLOW__API_AUTH__JWT_SECRET=airflow-shared-jwt-secret-key-2026
    command: api-server
    ports:
      - "8081:8080" # Airflow UI
    volumes:
      - ./dags:/opt/airflow/dags
      - ./config:/opt/airflow/config
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    depends_on:
      - airflow-init
    restart: unless-stopped
    networks:
      - agentic-network

  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow_scheduler
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:Gs+163264128@host.docker.internal:5433/controldb
      - AIRFLOW__CORE__FERNET_KEY=zTvhk7Vf2dHkL5j8g3nM9pQrYwXy4bCfE6HiJkLoNsU=
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__WEBSERVER__SECRET_KEY=super-secret-key-for-airflow
      - AIRFLOW__CORE__INTERNAL_API_URL=http://airflow-webserver:8080
      - AIRFLOW__CORE__EXECUTION_API_SERVER_URL=http://airflow-webserver:8080/execution/
      - AIRFLOW__API_AUTH__JWT_SECRET=airflow-shared-jwt-secret-key-2026
    command: scheduler
    volumes:
      - ./dags:/opt/airflow/dags
      - ./config:/opt/airflow/config
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./notebooks:/opt/airflow/notebooks
      - ./jars:/opt/spark/extra-jars
    depends_on:
      - airflow-init
    restart: unless-stopped
    networks:
      - agentic-network

  airflow-dag-processor:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow_dag_processor
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:Gs+163264128@host.docker.internal:5433/controldb
      - AIRFLOW__CORE__FERNET_KEY=zTvhk7Vf2dHkL5j8g3nM9pQrYwXy4bCfE6HiJkLoNsU=
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__WEBSERVER__SECRET_KEY=super-secret-key-for-airflow
      - AIRFLOW__CORE__INTERNAL_API_URL=http://airflow-webserver:8080
      - AIRFLOW__CORE__EXECUTION_API_SERVER_URL=http://airflow-webserver:8080/execution/
      - AIRFLOW__API_AUTH__JWT_SECRET=airflow-shared-jwt-secret-key-2026
    command: dag-processor
    volumes:
      - ./dags:/opt/airflow/dags
      - ./config:/opt/airflow/config
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    depends_on:
      - airflow-init
    restart: unless-stopped
    networks:
      - agentic-network

# ---------------------------------------------------------
# VOLUMES
# ---------------------------------------------------------
volumes:
  minio_data:
  marquez_db_data:


networks:
  agentic-network:
    driver: bridge
